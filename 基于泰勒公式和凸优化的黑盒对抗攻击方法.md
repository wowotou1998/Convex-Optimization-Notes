$$
\begin{array}{ll}
\underset{\mathbf{x}, \mathbf{y}_{i}, \mathbf{z}}{\operatorname{minimize}} & \left\|\mathbf{x}-\mathbf{x}_{0}\right\|_{p} \\
\text { subject to } & \mathbf{y}_{1}=\sigma\left(\mathbf{W}_{1} \mathbf{x}+\mathbf{b}_{1}\right) \\
& \mathbf{y}_{i}=\sigma\left(\mathbf{W}_{i} \mathbf{y}_{i-1}+\mathbf{b}_{i}\right), i=2, \ldots, N-1 \\
& \mathbf{z}=\mathbf{W}_{N} \mathbf{y}_{N-1}+\mathbf{b}_{N} \\
& \mathbf{z} \leq \mathbf{z}_{t} \mathbb{1}, 0 \leq \mathbf{x} \leq \mathbb{1}
\end{array}
$$
---------------------------------------

#### 关于神经网络的一些符号和定义
![avatar](D:/文档/+组会/DNNstructure.png)

设神经网络一共有$N+1$层(不包括输入层, 输出层), 第$N$层的输出结果为 $\mathbf{logits}$, 第$N+1$层为 $\text{softmax}$ 层, 则神经网络的数据处理过程:
$$
\begin{array}{rl}
 \mathbf{x}&=\mathbf{Input} \\
 \mathbf{y}_{1}&=\sigma\left(\mathbf{W}_{1} \mathbf{x}+\mathbf{b}_{1}\right) \\
 \mathbf{y}_{i}&=\sigma\left(\mathbf{W}_{i} \mathbf{y}_{i-1}+\mathbf{b}_{i}\right), i=2, \ldots, N-1 \\
 \mathbf{logits}&=\mathbf{W}_{N} \mathbf{y}_{N-1}+\mathbf{b}_{N} \\
 \mathbf{Output}&=\text{softmax}(\mathbf{logits}) \\
\end{array}
$$
设在 $\text{softmax}$ 层之前的输入(一般称之为 $\mathbf{logits}$ )为 $f_i(\mathbf{x}), i=1, \ldots, k$, 则 $F_i(x)$ 的结构如下所示:
$$
F_i(\mathbf{x}) = \frac{e^{f_i(\mathbf{x})}}{\sum_{j = 1}^{k} e^{f_j(\mathbf{x})}}
$$
尽管 $F_i(\mathbf{x})$ 结构如此复杂, 直接求导不方便, 但它是关于 $\mathbf{x}$ 的函数, 我们可以直接使用差分近似代替 $F_i(\mathbf{x})$ 的一阶导数.

#### 差分求导以及一阶泰勒展开
假设输入图片为 $\mathbf{x}$ ($\mathbf{x}$ 在这里可以看成一个常量), 且 $\mathbf{x}$ 中有 $n$ 个元素, 输出有 $k$ 个类别,设类别 $t$ 对应的概率值为 $F_t(\mathbf{x}), \ t=1, \ldots, k$.对于函数 $F_t(\mathbf{x})$, 我们使用差分近似的方法来求其在 $\mathbf{x}$ 处 一阶导数, 并使用一阶泰勒展开公式求得函数 $F_t(\mathbf{x})$ 在 $\mathbf{x+\delta}$ 处的近似值.
$$F_t(\mathbf{x+\delta}) \approx F_t(\mathbf{x}) + \delta  \nabla F_t(\mathbf{x})^T$$

#### 附加化简符号
设 $\mathbf{x}$ 为输入向量, $\delta$ 为扰动向量 , $\mathbf{1}$ 为分量全为1的向量,  $\epsilon$ 为分量全为极小值的向量.

令
$$
\begin{aligned}
\mathbf{z}  &= [ F_1(\mathbf{x+ \delta}), \ldots, F_k(\mathbf{x+ \delta}) ]\\
\mathbf{z}_t &= F_t(\mathbf{x+\delta}), \ t \in \{1, \ldots, k\}
\end{aligned}
$$

#### 有目标攻击
对于有目标攻击, 例如照片的真实标签为 $T$,  而我们希望神经网络分类结果为 $t$ ($T \neq t$),则:

$$
\text{max} [ F_1(\mathbf{x+ \delta}), \ldots, F_k(\mathbf{x+ \delta}) ] = F_{t}(\mathbf{x+\delta})
$$
则有如下不等式成立:
$$
\begin{aligned}
\mathbf{z} &\prec \mathbf{z}_{t} \mathbf{1}    \\
\mathbf{z}- \epsilon &\preceq \mathbf{z}_{t} \mathbf{1}
\end{aligned}
$$

对于有目标攻击的数学描述如下:
$$
\begin{array}{lll}
\underset{\delta }{\text{minimize}} & \left\| \delta \right\|_{p} &\\
              \text { subject to }  &  \mathbf{z}- \epsilon \preceq \mathbf{z}_{t} \mathbf{1} , & \ t \in \{1, \ldots, k\} \\
                                    &  \mathbf{(x+\delta)}_i \in [0,1],& \ i = 1,\ldots,n\\
\end{array}
$$
#### 对于有目标攻击问题的凸性证明
对于下列公式,我们可以展开证明.
$$
\begin{array}{lll}
\underset{\delta }{\text{minimize}} & \left\| \delta \right\|_{p} &\\
              \text { subject to }  &  \mathbf{z}- \epsilon \preceq \mathbf{z}_{t} \mathbf{1} , & \ t \in \{1, \ldots, k\} \\
                                    &  \mathbf{(x+\delta)}_i \in [0,1],& \ i = 1,\ldots,n\\
\end{array}
$$
等价于
$$
\begin{array}{lll}
\underset{\delta }{\text{minimize}} & \left\| \delta \right\|_{p} &\\
              \text { subject to }  &  \mathbf{z}- \epsilon - \mathbf{z}_{t} \mathbf{1} \preceq 0 , & \ t \in \{1, \ldots, k\} \\
                                    &  \mathbf{x+\delta} - \mathbf{1} \preceq \mathbf{0}          &\\
\end{array} \\
\tag{1.1}
$$


#### 无目标攻击
对于无目标攻击,我们希望 $F_t(\mathbf{x+\delta})$ ($t$ 是输入 $\mathbf{x}$ 的真实类别) 是所有输出的概率中的最小者, 即:
$$
F_t(\mathbf{x+\delta}) < \text{max} [ F_1(\mathbf{x+ \delta}), \ldots, F_k(\mathbf{x+ \delta}) ]
$$
则
$$
\begin{aligned}
F_t(\mathbf{x+\delta}) \mathbf{1} &\prec [ F_1(\mathbf{x+ \delta}), \ldots, F_k(\mathbf{x+ \delta}) ] \\
F_t(\mathbf{x+\delta}) \mathbf{1} &\preceq [ F_1(\mathbf{x+ \delta}), \ldots, F_k(\mathbf{x+ \delta}) ] - \epsilon
\end{aligned}
$$
等价于
$$
\begin{aligned}
\mathbf{z}_t \mathbf{1} &\prec \mathbf{z}  \\
\mathbf{z}_t \mathbf{1} &\preceq \mathbf{z}- \epsilon
\end{aligned}
$$


则对于无目标攻击的数学描述如下
$$
\begin{array}{lll}
\underset{\delta }{\text{minimize}} & \left\| \delta \right\|_{p} &\\
              \text { subject to }  & \mathbf{z}_t \mathbf{1} \preceq \mathbf{z}- \epsilon, & \ t \in \{1, \ldots, k\} \\
                                    &  \mathbf{(x+\delta)}_i \in [0,1],& \ i = 1,\ldots,n\\
\end{array}
$$





Copyright (c) 2018 Copyright Holder All Rights Reserved.
Copyright (c)




 Copyright Holder All Rights Reserved.
[doge]:data:image/png;base64,iVBORw0......
